{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip setuptools wheel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnhwO7uCvtKq",
        "outputId": "96df63af-54ca-4d24-f7d2-49e2df32128d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.3.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (75.6.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.45.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"numpy==1.24.4\" \"pandas==1.5.3\" \"scipy==1.10.1\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8syRwyswENq",
        "outputId": "ec7e6773-2ff1-4853-c991-24cf2780a0b2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.24.4 in /usr/local/lib/python3.10/dist-packages (1.24.4)\n",
            "Requirement already satisfied: pandas==1.5.3 in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: scipy==1.10.1 in /usr/local/lib/python3.10/dist-packages (1.10.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas==1.5.3) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"tensorflow==2.13.0\" \"ml-dtypes==0.3.1\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeJAW0Tywckx",
        "outputId": "5b356bc5-b8f5-44f4-f039-7de61c6f2ded"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.13.0 in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: ml-dtypes==0.3.1 in /usr/local/lib/python3.10/dist-packages (0.3.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (24.3.25)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.68.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.12.1)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (18.1.1)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.24.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (75.6.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.16.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.13.0) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update && apt-get install -y build-essential libffi-dev libssl-dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AQ6w8-Px9Zb",
        "outputId": "8783fb01-d7f7-4d2d-f9f7-79eabc67020f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,185 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,619 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,224 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,514 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,454 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,513 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,738 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [33.8 kB]\n",
            "Fetched 20.7 MB in 3s (8,114 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "libssl-dev is already the newest version (3.0.2-0ubuntu1.18).\n",
            "The following NEW packages will be installed:\n",
            "  libffi-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 59 not upgraded.\n",
            "Need to get 63.7 kB of archives.\n",
            "After this operation, 336 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libffi-dev amd64 3.4.2-4 [63.7 kB]\n",
            "Fetched 63.7 kB in 0s (129 kB/s)\n",
            "Selecting previously unselected package libffi-dev:amd64.\n",
            "(Reading database ... 123630 files and directories currently installed.)\n",
            "Preparing to unpack .../libffi-dev_3.4.2-4_amd64.deb ...\n",
            "Unpacking libffi-dev:amd64 (3.4.2-4) ...\n",
            "Setting up libffi-dev:amd64 (3.4.2-4) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"gym==0.25.2\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqTM__t6ypOE",
        "outputId": "6f4b9386-4d77-4846-b1a4-c7fa4e8f58a9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym==0.25.2 in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.25.2) (1.24.3)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.25.2) (3.1.0)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym==0.25.2) (0.0.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --no-deps \"stable-baselines3[extra]==1.6.2\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-WWj3hqy-vw",
        "outputId": "5c53b879-8459-4825-f7a2-9b23e9ec53ec"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stable-baselines3==1.6.2 (from stable-baselines3[extra]==1.6.2)\n",
            "  Downloading stable_baselines3-1.6.2-py3-none-any.whl.metadata (4.1 kB)\n",
            "Downloading stable_baselines3-1.6.2-py3-none-any.whl (170 kB)\n",
            "Installing collected packages: stable-baselines3\n",
            "Successfully installed stable-baselines3-1.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyYAML==6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IGCX6aCz0hT",
        "outputId": "36a3ee11-c832-4d26-99b2-60205e85cd41"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyYAML==6.0\n",
            "  Downloading PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (2.0 kB)\n",
            "Downloading PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (682 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/682.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m682.2/682.2 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyYAML\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "langchain-core 0.3.19 requires typing-extensions>=4.7, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyYAML-6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install aiohttp==3.8.1 websockets==9.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QXocBbG0Hiy",
        "outputId": "9cbc3914-9b3c-4278-b403-ecf0aa33a9f3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting aiohttp==3.8.1\n",
            "  Downloading aiohttp-3.8.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (7.3 kB)\n",
            "Collecting websockets==9.1\n",
            "  Downloading websockets-9.1.tar.gz (76 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.1) (24.2.0)\n",
            "Collecting charset-normalizer<3.0,>=2.0 (from aiohttp==3.8.1)\n",
            "  Downloading charset_normalizer-2.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.1) (6.1.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.1) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.1) (1.17.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.1) (1.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.1) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp==3.8.1) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp==3.8.1) (3.10)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp==3.8.1) (0.2.0)\n",
            "Downloading aiohttp-3.8.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
            "Building wheels for collected packages: websockets\n",
            "  Building wheel for websockets (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for websockets: filename=websockets-9.1-cp310-cp310-linux_x86_64.whl size=97278 sha256=99da04bedb7317b88321e40b8924bba0e09d6de82cbcfe2cb1aca899eed80fbc\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/f7/4e/873eca27ecd6d7230caff265283a5a5112ad4cd1d945c022dd\n",
            "Successfully built websockets\n",
            "Installing collected packages: websockets, charset-normalizer, aiohttp\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.0\n",
            "    Uninstalling charset-normalizer-3.4.0:\n",
            "      Successfully uninstalled charset-normalizer-3.4.0\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.11.2\n",
            "    Uninstalling aiohttp-3.11.2:\n",
            "      Successfully uninstalled aiohttp-3.11.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain 0.3.7 requires aiohttp<4.0.0,>=3.8.3, but you have aiohttp 3.8.1 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.13.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiohttp-3.8.1 charset-normalizer-2.1.1 websockets-9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import stable_baselines3\n",
        "print(\"gym and stable-baselines3 installed successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwS-sku_0MQ1",
        "outputId": "0e489b8e-5fee-4ec4-a048-95d1a00c2f38"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/util.py:52: DeprecationWarning: jax.xla_computation is deprecated. Please use the AOT APIs; see https://jax.readthedocs.io/en/latest/aot.html. For example, replace xla_computation(f)(*xs) with jit(f).lower(*xs).compiler_ir('hlo'). See CHANGELOG.md for 0.4.30 for more examples.\n",
            "  from jax import xla_computation as _xla_computation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gym and stable-baselines3 installed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/AI4Finance-Foundation/FinRL.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35sqtFQk0bNj",
        "outputId": "c380a0b4-303a-4699-bf66-27d5e09d3f22"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/AI4Finance-Foundation/FinRL.git\n",
            "  Cloning https://github.com/AI4Finance-Foundation/FinRL.git to /tmp/pip-req-build-3t59umxf\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/FinRL.git /tmp/pip-req-build-3t59umxf\n",
            "  Resolved https://github.com/AI4Finance-Foundation/FinRL.git to commit 083192a2abbdcaa195bd945b35853212cd8b00d8\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl (from finrl==0.3.6)\n",
            "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-qhq3485t/elegantrl_2b78781e00284ffcaead0a4f1f038323\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-qhq3485t/elegantrl_2b78781e00284ffcaead0a4f1f038323\n",
            "  Resolved https://github.com/AI4Finance-Foundation/ElegantRL.git to commit c2939fefe0e3ec55601ded49e39fdf9d7d781ea0\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: alpaca-trade-api<4,>=3 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (3.2.0)\n",
            "Requirement already satisfied: ccxt<4,>=3 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (3.1.60)\n",
            "Requirement already satisfied: exchange-calendars<5,>=4 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (4.6)\n",
            "Requirement already satisfied: jqdatasdk<2,>=1 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (1.9.6)\n",
            "Requirement already satisfied: pyfolio<0.10,>=0.9 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (0.9.2)\n",
            "Requirement already satisfied: pyportfolioopt<2,>=1 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (1.5.6)\n",
            "Requirement already satisfied: ray<3,>=2 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (2.39.0)\n",
            "Requirement already satisfied: scikit-learn<2,>=1 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (1.5.2)\n",
            "Requirement already satisfied: stable-baselines3>=2.0.0a5 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.5.0a0)\n",
            "Requirement already satisfied: stockstats<0.6,>=0.5 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (0.5.4)\n",
            "Requirement already satisfied: wrds<4,>=3 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (3.2.0)\n",
            "Requirement already satisfied: yfinance<0.3,>=0.2 in /usr/local/lib/python3.10/dist-packages (from finrl==0.3.6) (0.2.49)\n",
            "Requirement already satisfied: pandas>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (2.2.3)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>2 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (2.32.3)\n",
            "Requirement already satisfied: urllib3<2,>1.24 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (1.26.20)\n",
            "Requirement already satisfied: websocket-client<2,>=0.56.0 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (1.8.0)\n",
            "Requirement already satisfied: websockets<11,>=9.0 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (9.1)\n",
            "Requirement already satisfied: msgpack==1.0.3 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (1.0.3)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (3.11.9)\n",
            "Requirement already satisfied: PyYAML==6.0.1 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (6.0.1)\n",
            "Requirement already satisfied: deprecation==2.1.0 in /usr/local/lib/python3.10/dist-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (2.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from deprecation==2.1.0->alpaca-trade-api<4,>=3->finrl==0.3.6) (23.2)\n",
            "Requirement already satisfied: setuptools>=60.9.0 in /usr/local/lib/python3.10/dist-packages (from ccxt<4,>=3->finrl==0.3.6) (75.6.0)\n",
            "Requirement already satisfied: certifi>=2018.1.18 in /usr/local/lib/python3.10/dist-packages (from ccxt<4,>=3->finrl==0.3.6) (2024.8.30)\n",
            "Requirement already satisfied: cryptography>=2.6.1 in /usr/local/lib/python3.10/dist-packages (from ccxt<4,>=3->finrl==0.3.6) (43.0.3)\n",
            "Requirement already satisfied: aiodns>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from ccxt<4,>=3->finrl==0.3.6) (3.2.0)\n",
            "Requirement already satisfied: yarl>=1.7.2 in /usr/local/lib/python3.10/dist-packages (from ccxt<4,>=3->finrl==0.3.6) (1.17.2)\n",
            "Requirement already satisfied: pyluach in /usr/local/lib/python3.10/dist-packages (from exchange-calendars<5,>=4->finrl==0.3.6) (2.2.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from exchange-calendars<5,>=4->finrl==0.3.6) (0.12.1)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.10/dist-packages (from exchange-calendars<5,>=4->finrl==0.3.6) (2024.2)\n",
            "Requirement already satisfied: korean_lunar_calendar in /usr/local/lib/python3.10/dist-packages (from exchange-calendars<5,>=4->finrl==0.3.6) (0.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from jqdatasdk<2,>=1->finrl==0.3.6) (1.16.0)\n",
            "Requirement already satisfied: SQLAlchemy>=1.2.8 in /usr/local/lib/python3.10/dist-packages (from jqdatasdk<2,>=1->finrl==0.3.6) (2.0.36)\n",
            "Requirement already satisfied: pymysql>=0.7.6 in /usr/local/lib/python3.10/dist-packages (from jqdatasdk<2,>=1->finrl==0.3.6) (1.1.1)\n",
            "Requirement already satisfied: thriftpy2!=0.5.1,>=0.3.9 in /usr/local/lib/python3.10/dist-packages (from jqdatasdk<2,>=1->finrl==0.3.6) (0.5.2)\n",
            "Requirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.10/dist-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (7.34.0)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (3.8.0)\n",
            "Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.10/dist-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (2024.2)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (1.12.0)\n",
            "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (0.13.2)\n",
            "Requirement already satisfied: empyrical>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (0.5.5)\n",
            "Requirement already satisfied: cvxpy>=1.1.19 in /usr/local/lib/python3.10/dist-packages (from pyportfolioopt<2,>=1->finrl==0.3.6) (1.5.4)\n",
            "Requirement already satisfied: ecos<3.0.0,>=2.0.14 in /usr/local/lib/python3.10/dist-packages (from pyportfolioopt<2,>=1->finrl==0.3.6) (2.0.14)\n",
            "Requirement already satisfied: plotly<6.0.0,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from pyportfolioopt<2,>=1->finrl==0.3.6) (5.24.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (3.16.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (4.23.0)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (4.25.5)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (1.5.0)\n",
            "Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (0.7.0)\n",
            "Requirement already satisfied: colorful in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (0.5.6)\n",
            "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (0.4.0)\n",
            "Requirement already satisfied: opencensus in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (0.11.4)\n",
            "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (2.9.2)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (0.21.0)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (7.0.5)\n",
            "Requirement already satisfied: virtualenv!=20.21.1,>=20.0.24 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (20.28.0)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (1.68.0)\n",
            "Requirement already satisfied: memray in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (1.14.0)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (2.6.2.2)\n",
            "Requirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (17.0.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (2024.10.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2,>=1->finrl==0.3.6) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2,>=1->finrl==0.3.6) (3.5.0)\n",
            "Requirement already satisfied: gymnasium<1.1.0,>=0.29.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (1.0.0)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.5.1+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.1.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (4.10.0.84)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.13.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (4.66.6)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (13.9.4)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.10.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (11.0.0)\n",
            "Requirement already satisfied: psycopg2-binary<2.10,>=2.9 in /usr/local/lib/python3.10/dist-packages (from wrds<4,>=3->finrl==0.3.6) (2.9.10)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (5.3.0)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (4.3.6)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (3.17.8)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (4.12.3)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (1.1)\n",
            "Requirement already satisfied: th in /usr/local/lib/python3.10/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.6) (0.4.1)\n",
            "Requirement already satisfied: pycares>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from aiodns>=1.1.1->ccxt<4,>=3->finrl==0.3.6) (4.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.6) (2.4.3)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.6) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.6) (24.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.6) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.6) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from ale-py>=0.9.0->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (4.12.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance<0.3,>=0.2->finrl==0.3.6) (2.6)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.6.1->ccxt<4,>=3->finrl==0.3.6) (1.17.1)\n",
            "Requirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from cvxpy>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6) (0.6.7.post3)\n",
            "Requirement already satisfied: clarabel>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from cvxpy>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6) (0.9.0)\n",
            "Requirement already satisfied: scs>=3.2.4.post1 in /usr/local/lib/python3.10/dist-packages (from cvxpy>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6) (3.2.7)\n",
            "Requirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.10/dist-packages (from empyrical>=0.5.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.10.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.0.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance<0.3,>=0.2->finrl==0.3.6) (0.5.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (4.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (2.8.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly<6.0.0,>=5.0.0->pyportfolioopt<2,>=1->finrl==0.3.6) (9.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[default,tune]<3,>=2->finrl==0.3.6) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[default,tune]<3,>=2->finrl==0.3.6) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>2->alpaca-trade-api<4,>=3->finrl==0.3.6) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>2->alpaca-trade-api<4,>=3->finrl==0.3.6) (3.10)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.2.8->jqdatasdk<2,>=1->finrl==0.3.6) (3.1.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (1.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.1.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.45.1)\n",
            "Requirement already satisfied: Cython>=3.0.10 in /usr/local/lib/python3.10/dist-packages (from thriftpy2!=0.5.1,>=0.3.9->jqdatasdk<2,>=1->finrl==0.3.6) (3.0.11)\n",
            "Requirement already satisfied: ply<4.0,>=3.4 in /usr/local/lib/python3.10/dist-packages (from thriftpy2!=0.5.1,>=0.3.9->jqdatasdk<2,>=1->finrl==0.3.6) (3.11)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (1.3.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<3,>=2->finrl==0.3.6) (0.3.9)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6) (0.21.0)\n",
            "Requirement already satisfied: textual>=0.41.0 in /usr/local/lib/python3.10/dist-packages (from memray->ray[default,tune]<3,>=2->finrl==0.3.6) (0.88.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.0.0)\n",
            "Requirement already satisfied: opencensus-context>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[default,tune]<3,>=2->finrl==0.3.6) (0.1.3)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[default,tune]<3,>=2->finrl==0.3.6) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open->ray[default,tune]<3,>=2->finrl==0.3.6) (1.16.0)\n",
            "Requirement already satisfied: niltype<2.0,>=0.3 in /usr/local/lib/python3.10/dist-packages (from th->elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.6) (1.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt<4,>=3->finrl==0.3.6) (2.22)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.6) (1.66.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.6) (1.25.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.8.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.0.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.1.2)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.10/dist-packages (from osqp>=0.6.2->cvxpy>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6) (0.1.7.post4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.2.13)\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<3,>=2->finrl==0.3.6) (2.0.3)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<3,>=2->finrl==0.3.6) (0.4.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.2.2)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<3,>=2->finrl==0.3.6) (1.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "5fJ4ljKu1qTm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime"
      ],
      "metadata": {
        "id": "owymmwwb65C9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "XtPV08LR7EDJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
        "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
        "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
        "from finrl.agents.stablebaselines3.models import DRLAgent, DRLEnsembleAgent\n",
        "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline"
      ],
      "metadata": {
        "id": "Br4rPq9OpUfr"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import DQN"
      ],
      "metadata": {
        "id": "dBKKBt8z6mp3"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from finrl.config import (\n",
        "    DATA_SAVE_DIR,\n",
        "    TRAINED_MODEL_DIR,\n",
        "    TENSORBOARD_LOG_DIR,\n",
        "    RESULTS_DIR,\n",
        "    INDICATORS,\n",
        "    TRAIN_START_DATE,\n",
        "    TRAIN_END_DATE,\n",
        "    TEST_START_DATE,\n",
        "    TEST_END_DATE,\n",
        "    TRADE_START_DATE,\n",
        "    TRADE_END_DATE,\n",
        ")"
      ],
      "metadata": {
        "id": "k0CcQ1qYpXoF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from finrl.main import check_and_make_directories\n",
        "import os"
      ],
      "metadata": {
        "id": "hb2rvmn5pdkw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"
      ],
      "metadata": {
        "id": "C0oPmrJGpfKW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_START_DATE = \"2012-01-01\"\n",
        "TRAIN_END_DATE = \"2018-12-31\"\n",
        "TEST_START_DATE = \"2019-01-01\"\n",
        "TEST_END_DATE = \"2022-12-31\""
      ],
      "metadata": {
        "id": "lkTofjogphCv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ticker = ['AAPL', 'MSFT', 'TSLA']\n",
        "df = YahooDownloader(start_date = TRAIN_START_DATE,\n",
        "                     end_date = TEST_END_DATE,\n",
        "                     ticker_list = ticker).fetch_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8E8rzKoxptKy",
        "outputId": "18f2c2b7-824a-40a5-9bbd-b1d815d38953"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of DataFrame:  (8304, 8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JAc4NuZnqxjo",
        "outputId": "047fa847-a765-4c23-a5ec-36e54a462cf2"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         date       open       high        low      close     volume   tic  \\\n",
              "0  2012-01-03  12.389001  14.686786  14.732143  14.621429  302220800  AAPL   \n",
              "1  2012-01-03  21.120098  26.770000  26.959999  26.549999   64731500  MSFT   \n",
              "2  2012-01-03   1.872000   1.872000   1.966667   1.929333   13921500  TSLA   \n",
              "3  2012-01-04  12.455576  14.765714  14.810000  14.642857  260022000  AAPL   \n",
              "4  2012-01-04  21.617128  27.400000  27.469999  26.820000   80516100  MSFT   \n",
              "\n",
              "   day  \n",
              "0    1  \n",
              "1    1  \n",
              "2    1  \n",
              "3    2  \n",
              "4    2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3420b319-bc9e-4424-b886-d241b393552f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-01-03</td>\n",
              "      <td>12.389001</td>\n",
              "      <td>14.686786</td>\n",
              "      <td>14.732143</td>\n",
              "      <td>14.621429</td>\n",
              "      <td>302220800</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2012-01-03</td>\n",
              "      <td>21.120098</td>\n",
              "      <td>26.770000</td>\n",
              "      <td>26.959999</td>\n",
              "      <td>26.549999</td>\n",
              "      <td>64731500</td>\n",
              "      <td>MSFT</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2012-01-03</td>\n",
              "      <td>1.872000</td>\n",
              "      <td>1.872000</td>\n",
              "      <td>1.966667</td>\n",
              "      <td>1.929333</td>\n",
              "      <td>13921500</td>\n",
              "      <td>TSLA</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012-01-04</td>\n",
              "      <td>12.455576</td>\n",
              "      <td>14.765714</td>\n",
              "      <td>14.810000</td>\n",
              "      <td>14.642857</td>\n",
              "      <td>260022000</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2012-01-04</td>\n",
              "      <td>21.617128</td>\n",
              "      <td>27.400000</td>\n",
              "      <td>27.469999</td>\n",
              "      <td>26.820000</td>\n",
              "      <td>80516100</td>\n",
              "      <td>MSFT</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3420b319-bc9e-4424-b886-d241b393552f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3420b319-bc9e-4424-b886-d241b393552f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3420b319-bc9e-4424-b886-d241b393552f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9850206a-c9eb-4c38-b105-1144c55df0be\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9850206a-c9eb-4c38-b105-1144c55df0be')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9850206a-c9eb-4c38-b105-1144c55df0be button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8304,\n  \"fields\": [\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 2768,\n        \"samples\": [\n          \"2017-06-26\",\n          \"2015-05-06\",\n          \"2020-08-10\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 84.83027041468942,\n        \"min\": 1.519333004951477,\n        \"max\": 409.9700012207031,\n        \"num_unique_values\": 8026,\n        \"samples\": [\n          53.599998474121094,\n          26.8155574798584,\n          15.183333396911621\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"high\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 85.5741796393586,\n        \"min\": 1.519333004951477,\n        \"max\": 409.9700012207031,\n        \"num_unique_values\": 7603,\n        \"samples\": [\n          29.75749969482422,\n          31.107500076293945,\n          55.66666793823242\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 86.98417030873686,\n        \"min\": 1.7899999618530273,\n        \"max\": 414.4966735839844,\n        \"num_unique_values\": 7467,\n        \"samples\": [\n          51.790000915527344,\n          108.30000305175781,\n          37.54999923706055\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 85.61730368405107,\n        \"min\": 1.7746670246124268,\n        \"max\": 411.4700012207031,\n        \"num_unique_values\": 7541,\n        \"samples\": [\n          56.0,\n          188.05999755859375,\n          40.45000076293945\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 130455002,\n        \"min\": 5473500,\n        \"max\": 1506120000,\n        \"num_unique_values\": 8264,\n        \"samples\": [\n          147713200,\n          126585600,\n          48011800\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tic\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"AAPL\",\n          \"MSFT\",\n          \"TSLA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          0,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "nC8z54e8q5vx",
        "outputId": "7feec905-d87c-43ae-b433-f50bb74c8a51"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            date        open        high         low       close     volume  \\\n",
              "8299  2022-12-29  237.118607  241.009995  241.919998  235.649994   19770700   \n",
              "8300  2022-12-29  121.820000  121.820000  123.570000  120.389999  221923300   \n",
              "8301  2022-12-30  128.577881  129.929993  129.949997  128.410004   77034200   \n",
              "8302  2022-12-30  235.947845  239.820007  239.960007  238.210007   21938500   \n",
              "8303  2022-12-30  123.180000  123.180000  124.480003  119.949997  157777300   \n",
              "\n",
              "       tic  day  \n",
              "8299  MSFT    3  \n",
              "8300  TSLA    3  \n",
              "8301  AAPL    4  \n",
              "8302  MSFT    4  \n",
              "8303  TSLA    4  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0f14d81f-eccc-4002-ac3d-73d53bd04803\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8299</th>\n",
              "      <td>2022-12-29</td>\n",
              "      <td>237.118607</td>\n",
              "      <td>241.009995</td>\n",
              "      <td>241.919998</td>\n",
              "      <td>235.649994</td>\n",
              "      <td>19770700</td>\n",
              "      <td>MSFT</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8300</th>\n",
              "      <td>2022-12-29</td>\n",
              "      <td>121.820000</td>\n",
              "      <td>121.820000</td>\n",
              "      <td>123.570000</td>\n",
              "      <td>120.389999</td>\n",
              "      <td>221923300</td>\n",
              "      <td>TSLA</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8301</th>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>128.577881</td>\n",
              "      <td>129.929993</td>\n",
              "      <td>129.949997</td>\n",
              "      <td>128.410004</td>\n",
              "      <td>77034200</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8302</th>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>235.947845</td>\n",
              "      <td>239.820007</td>\n",
              "      <td>239.960007</td>\n",
              "      <td>238.210007</td>\n",
              "      <td>21938500</td>\n",
              "      <td>MSFT</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8303</th>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>123.180000</td>\n",
              "      <td>123.180000</td>\n",
              "      <td>124.480003</td>\n",
              "      <td>119.949997</td>\n",
              "      <td>157777300</td>\n",
              "      <td>TSLA</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f14d81f-eccc-4002-ac3d-73d53bd04803')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0f14d81f-eccc-4002-ac3d-73d53bd04803 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0f14d81f-eccc-4002-ac3d-73d53bd04803');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-64cb2cef-ae63-41ac-accb-b9008b92772b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-64cb2cef-ae63-41ac-accb-b9008b92772b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-64cb2cef-ae63-41ac-accb-b9008b92772b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "0"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKHwjUXbq7YU",
        "outputId": "b780c760-4b56-44f9-c64b-c04a04d99645"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8304, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.sort_values(['date','tic']).head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rchKj6jgrCFg",
        "outputId": "19f0aaca-f684-407e-ae56-e91ccd518ed5"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         date       open       high        low      close     volume   tic  \\\n",
              "0  2012-01-03  12.389001  14.686786  14.732143  14.621429  302220800  AAPL   \n",
              "1  2012-01-03  21.120098  26.770000  26.959999  26.549999   64731500  MSFT   \n",
              "2  2012-01-03   1.872000   1.872000   1.966667   1.929333   13921500  TSLA   \n",
              "3  2012-01-04  12.455576  14.765714  14.810000  14.642857  260022000  AAPL   \n",
              "4  2012-01-04  21.617128  27.400000  27.469999  26.820000   80516100  MSFT   \n",
              "\n",
              "   day  \n",
              "0    1  \n",
              "1    1  \n",
              "2    1  \n",
              "3    2  \n",
              "4    2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df58b096-1bc3-46f1-a5c8-a73217458f8d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-01-03</td>\n",
              "      <td>12.389001</td>\n",
              "      <td>14.686786</td>\n",
              "      <td>14.732143</td>\n",
              "      <td>14.621429</td>\n",
              "      <td>302220800</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2012-01-03</td>\n",
              "      <td>21.120098</td>\n",
              "      <td>26.770000</td>\n",
              "      <td>26.959999</td>\n",
              "      <td>26.549999</td>\n",
              "      <td>64731500</td>\n",
              "      <td>MSFT</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2012-01-03</td>\n",
              "      <td>1.872000</td>\n",
              "      <td>1.872000</td>\n",
              "      <td>1.966667</td>\n",
              "      <td>1.929333</td>\n",
              "      <td>13921500</td>\n",
              "      <td>TSLA</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012-01-04</td>\n",
              "      <td>12.455576</td>\n",
              "      <td>14.765714</td>\n",
              "      <td>14.810000</td>\n",
              "      <td>14.642857</td>\n",
              "      <td>260022000</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2012-01-04</td>\n",
              "      <td>21.617128</td>\n",
              "      <td>27.400000</td>\n",
              "      <td>27.469999</td>\n",
              "      <td>26.820000</td>\n",
              "      <td>80516100</td>\n",
              "      <td>MSFT</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df58b096-1bc3-46f1-a5c8-a73217458f8d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-df58b096-1bc3-46f1-a5c8-a73217458f8d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-df58b096-1bc3-46f1-a5c8-a73217458f8d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-19ad2bcd-a6b3-4647-bddb-41b8656e8940\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-19ad2bcd-a6b3-4647-bddb-41b8656e8940')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-19ad2bcd-a6b3-4647-bddb-41b8656e8940 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"2012-01-04\",\n          \"2012-01-03\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.073501779362818,\n        \"min\": 1.871999979019165,\n        \"max\": 21.617128372192383,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          21.120098114013672,\n          21.617128372192383\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"high\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.52097162123572,\n        \"min\": 1.871999979019165,\n        \"max\": 27.399999618530273,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          26.770000457763672,\n          27.399999618530273\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.542610752637342,\n        \"min\": 1.9666670560836792,\n        \"max\": 27.469999313354492,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          26.959999084472656,\n          27.469999313354492\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.31910268830665,\n        \"min\": 1.929332971572876,\n        \"max\": 26.81999969482422,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          26.549999237060547,\n          26.81999969482422\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 128187991,\n        \"min\": 13921500,\n        \"max\": 302220800,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          64731500,\n          80516100\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tic\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"AAPL\",\n          \"MSFT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INDICATORS = ['macd',\n",
        "               'rsi_30',\n",
        "               'cci_30',\n",
        "               'dx_30']"
      ],
      "metadata": {
        "id": "FKj2QxLLrLnU"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fe = FeatureEngineer(use_technical_indicator=True,\n",
        "                     tech_indicator_list = INDICATORS,\n",
        "                     use_turbulence=True,\n",
        "                     user_defined_feature = False)\n",
        "\n",
        "processed = fe.preprocess_data(df)\n",
        "processed = processed.copy()\n",
        "processed = processed.fillna(0)\n",
        "processed = processed.replace(np.inf,0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlSCxwbirO7u",
        "outputId": "9a784c81-ec31-4eae-c803-158f4e204a28"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully added technical indicators\n",
            "Successfully added turbulence index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CixIcTsEsEc6",
        "outputId": "2cb35b1c-a755-4de5-ccff-8688320a1538"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            date        open        high         low       close     volume  \\\n",
              "3578  2016-09-28   13.751333   13.751333   13.883333   13.834000   31326000   \n",
              "7919  2022-06-29  228.490005  228.490005  231.173340  230.500000   82897200   \n",
              "3204  2016-04-04   25.303989   27.780001   28.047501   27.605000  149424800   \n",
              "2343  2015-02-11   27.919825   31.219999   31.230000   30.692499  294247200   \n",
              "5859  2019-10-08   54.225170   56.099998   57.014999   56.455002  111820000   \n",
              "\n",
              "       tic  day      macd     rsi_30      cci_30      dx_30  turbulence  \n",
              "3578  TSLA    2 -0.158332  46.218564  -22.093057   9.790670    1.439076  \n",
              "7919  TSLA    2 -5.257982  44.301740  -46.527936  14.393473    3.081052  \n",
              "3204  AAPL    0  0.633755  59.297707  144.836534  54.639978    0.552877  \n",
              "2343  AAPL    2  0.648710  61.678688  163.543982  58.882094    3.978813  \n",
              "5859  AAPL    1  0.841459  59.228332  100.260900  14.383293    1.000334  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ca498c58-b797-4733-91a1-3a3f5d26f896\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>turbulence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3578</th>\n",
              "      <td>2016-09-28</td>\n",
              "      <td>13.751333</td>\n",
              "      <td>13.751333</td>\n",
              "      <td>13.883333</td>\n",
              "      <td>13.834000</td>\n",
              "      <td>31326000</td>\n",
              "      <td>TSLA</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.158332</td>\n",
              "      <td>46.218564</td>\n",
              "      <td>-22.093057</td>\n",
              "      <td>9.790670</td>\n",
              "      <td>1.439076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7919</th>\n",
              "      <td>2022-06-29</td>\n",
              "      <td>228.490005</td>\n",
              "      <td>228.490005</td>\n",
              "      <td>231.173340</td>\n",
              "      <td>230.500000</td>\n",
              "      <td>82897200</td>\n",
              "      <td>TSLA</td>\n",
              "      <td>2</td>\n",
              "      <td>-5.257982</td>\n",
              "      <td>44.301740</td>\n",
              "      <td>-46.527936</td>\n",
              "      <td>14.393473</td>\n",
              "      <td>3.081052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3204</th>\n",
              "      <td>2016-04-04</td>\n",
              "      <td>25.303989</td>\n",
              "      <td>27.780001</td>\n",
              "      <td>28.047501</td>\n",
              "      <td>27.605000</td>\n",
              "      <td>149424800</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>0</td>\n",
              "      <td>0.633755</td>\n",
              "      <td>59.297707</td>\n",
              "      <td>144.836534</td>\n",
              "      <td>54.639978</td>\n",
              "      <td>0.552877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2343</th>\n",
              "      <td>2015-02-11</td>\n",
              "      <td>27.919825</td>\n",
              "      <td>31.219999</td>\n",
              "      <td>31.230000</td>\n",
              "      <td>30.692499</td>\n",
              "      <td>294247200</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>2</td>\n",
              "      <td>0.648710</td>\n",
              "      <td>61.678688</td>\n",
              "      <td>163.543982</td>\n",
              "      <td>58.882094</td>\n",
              "      <td>3.978813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5859</th>\n",
              "      <td>2019-10-08</td>\n",
              "      <td>54.225170</td>\n",
              "      <td>56.099998</td>\n",
              "      <td>57.014999</td>\n",
              "      <td>56.455002</td>\n",
              "      <td>111820000</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>1</td>\n",
              "      <td>0.841459</td>\n",
              "      <td>59.228332</td>\n",
              "      <td>100.260900</td>\n",
              "      <td>14.383293</td>\n",
              "      <td>1.000334</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca498c58-b797-4733-91a1-3a3f5d26f896')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ca498c58-b797-4733-91a1-3a3f5d26f896 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ca498c58-b797-4733-91a1-3a3f5d26f896');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fe1291a7-8a3d-44dc-b1f3-a126693ceb4d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fe1291a7-8a3d-44dc-b1f3-a126693ceb4d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fe1291a7-8a3d-44dc-b1f3-a126693ceb4d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "0"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stock_dimension = len(processed.tic.unique())\n",
        "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWWbsdZFsIoh",
        "outputId": "5cba11c4-adfa-460b-b95e-73fd4056a085"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stock Dimension: 3, State Space: 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env_kwargs = {\n",
        "    \"hmax\": 100,\n",
        "    \"initial_amount\": 1000000,\n",
        "    \"buy_cost_pct\": 0.001,\n",
        "    \"sell_cost_pct\": 0.001,\n",
        "    \"state_space\": state_space,\n",
        "    \"stock_dim\": stock_dimension,\n",
        "    \"tech_indicator_list\": INDICATORS,\n",
        "    \"action_space\": stock_dimension,\n",
        "    \"reward_scaling\": 1e-4,\n",
        "    \"print_verbosity\":5\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "vFtleu10shqs"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rebalance_window = 63 # rebalance_window is the number of days to retrain the model\n",
        "validation_window = 63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\n",
        "\n",
        "ensemble_agent = DRLEnsembleAgent(df=processed,\n",
        "                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n",
        "                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n",
        "                 rebalance_window=rebalance_window,\n",
        "                 validation_window=validation_window,\n",
        "                 **env_kwargs)"
      ],
      "metadata": {
        "id": "ok-IOeKltGtn"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A2C_model_kwargs = {\n",
        "                    'n_steps': 5,\n",
        "                    'ent_coef': 0.005,\n",
        "                    'learning_rate': 0.0007\n",
        "                    }\n",
        "\n",
        "PPO_model_kwargs = {\n",
        "                    \"ent_coef\":0.01,\n",
        "                    \"n_steps\": 2048,\n",
        "                    \"learning_rate\": 0.00025,\n",
        "                    \"batch_size\": 128\n",
        "                    }\n",
        "\n",
        "DDPG_model_kwargs = {\n",
        "                      #\"action_noise\":\"ornstein_uhlenbeck\",\n",
        "                      \"buffer_size\": 10_000,\n",
        "                      \"learning_rate\": 0.0005,\n",
        "                      \"batch_size\": 64\n",
        "                    }\n",
        "TD3_model_kwargs = {}\n",
        "SAC_model_kwargs = {}\n",
        "\n",
        "timesteps_dict = {'a2c' : 10_000,\n",
        "                 'ppo' : 10_000,\n",
        "                 'ddpg' : 10_000,\n",
        "                  \"td3\": 10_000,\n",
        "                  \"sac\": 10_000\n",
        "                 }"
      ],
      "metadata": {
        "id": "huqXQvlzyoJY"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_summary = ensemble_agent.run_ensemble_strategy(\n",
        "    A2C_model_kwargs=A2C_model_kwargs,\n",
        "    PPO_model_kwargs=PPO_model_kwargs,\n",
        "    DDPG_model_kwargs=DDPG_model_kwargs,\n",
        "    TD3_model_kwargs=TD3_model_kwargs,  # Include this argument\n",
        "    SAC_model_kwargs=SAC_model_kwargs,\n",
        "    timesteps_dict=timesteps_dict\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C56ps-hv8rOz",
        "outputId": "8e41a739-c762-4305-a859-f977ac914c43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============Start Ensemble Strategy============\n",
            "============================================\n",
            "turbulence_threshold:  24.528961738292235\n",
            "======Model training from:  2012-01-01 to  2019-01-02\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_126_1\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 264         |\n",
            "|    iterations         | 100         |\n",
            "|    time_elapsed       | 1           |\n",
            "|    total_timesteps    | 500         |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.4        |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 99          |\n",
            "|    policy_loss        | -4.89       |\n",
            "|    reward             | -0.80067116 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 1.99        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 275        |\n",
            "|    iterations         | 200        |\n",
            "|    time_elapsed       | 3          |\n",
            "|    total_timesteps    | 1000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.4       |\n",
            "|    explained_variance | -0.0232    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 199        |\n",
            "|    policy_loss        | 0.834      |\n",
            "|    reward             | 0.35207003 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 2.1        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 280       |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 5         |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.41     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | 24        |\n",
            "|    reward             | 2.7371593 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 23.2      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 282         |\n",
            "|    iterations         | 400         |\n",
            "|    time_elapsed       | 7           |\n",
            "|    total_timesteps    | 2000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.43       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 399         |\n",
            "|    policy_loss        | 0.0396      |\n",
            "|    reward             | -0.04545635 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 0.000754    |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 276        |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 9          |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.44      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | -10.5      |\n",
            "|    reward             | -0.8061622 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 8.59       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 256       |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 11        |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.43     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | 6.89      |\n",
            "|    reward             | 0.9762218 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 4.46      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 258       |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 13        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.44     |\n",
            "|    explained_variance | -0.0267   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | -36.3     |\n",
            "|    reward             | -2.391462 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 44.5      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 261       |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 15        |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.42     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | -5.14     |\n",
            "|    reward             | 1.7450564 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 5.29      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 263        |\n",
            "|    iterations         | 900        |\n",
            "|    time_elapsed       | 17         |\n",
            "|    total_timesteps    | 4500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.44      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 899        |\n",
            "|    policy_loss        | -2.96      |\n",
            "|    reward             | -1.0379066 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 7.02       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 266       |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 18        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.45     |\n",
            "|    explained_variance | -0.0049   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | -1.45     |\n",
            "|    reward             | 6.3502755 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 2.49      |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 268          |\n",
            "|    iterations         | 1100         |\n",
            "|    time_elapsed       | 20           |\n",
            "|    total_timesteps    | 5500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.46        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1099         |\n",
            "|    policy_loss        | -0.0921      |\n",
            "|    reward             | -0.027914353 |\n",
            "|    std                | 1.07         |\n",
            "|    value_loss         | 0.00548      |\n",
            "----------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 267      |\n",
            "|    iterations         | 1200     |\n",
            "|    time_elapsed       | 22       |\n",
            "|    total_timesteps    | 6000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.45    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1199     |\n",
            "|    policy_loss        | 0.508    |\n",
            "|    reward             | 2.673384 |\n",
            "|    std                | 1.07     |\n",
            "|    value_loss         | 0.489    |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 259       |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 25        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.46     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | -4.34     |\n",
            "|    reward             | 2.6805656 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 5.85      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 258      |\n",
            "|    iterations         | 1400     |\n",
            "|    time_elapsed       | 27       |\n",
            "|    total_timesteps    | 7000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.47    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1399     |\n",
            "|    policy_loss        | 113      |\n",
            "|    reward             | 3.648235 |\n",
            "|    std                | 1.07     |\n",
            "|    value_loss         | 865      |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 260        |\n",
            "|    iterations         | 1500       |\n",
            "|    time_elapsed       | 28         |\n",
            "|    total_timesteps    | 7500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.48      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1499       |\n",
            "|    policy_loss        | -17        |\n",
            "|    reward             | -1.8049977 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 15.6       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 262       |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 30        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.46     |\n",
            "|    explained_variance | -0.0111   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | 18.7      |\n",
            "|    reward             | 3.1502407 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 17.6      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 263         |\n",
            "|    iterations         | 1700        |\n",
            "|    time_elapsed       | 32          |\n",
            "|    total_timesteps    | 8500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.47       |\n",
            "|    explained_variance | -0.0384     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1699        |\n",
            "|    policy_loss        | 18.5        |\n",
            "|    reward             | -0.78655875 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 15.9        |\n",
            "---------------------------------------\n",
            "day: 1759, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 2541423.02\n",
            "total_reward: 1541423.02\n",
            "total_cost: 9965.28\n",
            "total_trades: 4540\n",
            "Sharpe: 0.640\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 264         |\n",
            "|    iterations         | 1800        |\n",
            "|    time_elapsed       | 33          |\n",
            "|    total_timesteps    | 9000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.47       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1799        |\n",
            "|    policy_loss        | -4.25       |\n",
            "|    reward             | -0.09403906 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 0.715       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 265        |\n",
            "|    iterations         | 1900       |\n",
            "|    time_elapsed       | 35         |\n",
            "|    total_timesteps    | 9500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.45      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1899       |\n",
            "|    policy_loss        | 3.7        |\n",
            "|    reward             | -4.3881817 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 3.52       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 261        |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 38         |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.43      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | 7.81       |\n",
            "|    reward             | 0.36191243 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 4.5        |\n",
            "--------------------------------------\n",
            "======a2c Validation from:  2019-01-02 to  2019-04-03\n",
            "a2c Sharpe Ratio:  0.2572098903640918\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_126_1\n",
            "day: 1759, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 2111076.60\n",
            "total_reward: 1111076.60\n",
            "total_cost: 998.99\n",
            "total_trades: 1759\n",
            "Sharpe: 0.568\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 47        |\n",
            "|    time_elapsed    | 149       |\n",
            "|    total_timesteps | 7040      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -2.97e+03 |\n",
            "|    critic_loss     | 2.35e+07  |\n",
            "|    learning_rate   | 0.0005    |\n",
            "|    n_updates       | 6939      |\n",
            "|    reward          | 1.3715979 |\n",
            "----------------------------------\n",
            "======ddpg Validation from:  2019-01-02 to  2019-04-03\n",
            "ddpg Sharpe Ratio:  0.47997054861213995\n",
            "======td3 Training========\n",
            "{}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/td3/td3_126_1\n",
            "day: 1759, episode: 15\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3430193.64\n",
            "total_reward: 2430193.64\n",
            "total_cost: 998.99\n",
            "total_trades: 1759\n",
            "Sharpe: 0.918\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 4          |\n",
            "|    fps             | 27         |\n",
            "|    time_elapsed    | 254        |\n",
            "|    total_timesteps | 7040       |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 1.02e+03   |\n",
            "|    critic_loss     | 58.5       |\n",
            "|    learning_rate   | 0.001      |\n",
            "|    n_updates       | 6939       |\n",
            "|    reward          | -2.7091844 |\n",
            "-----------------------------------\n",
            "======td3 Validation from:  2019-01-02 to  2019-04-03\n",
            "td3 Sharpe Ratio:  0.40969072292960185\n",
            "======sac Training========\n",
            "{}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/sac/sac_126_1\n",
            "day: 1759, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3430193.64\n",
            "total_reward: 2430193.64\n",
            "total_cost: 998.99\n",
            "total_trades: 1759\n",
            "Sharpe: 0.918\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 4          |\n",
            "|    fps             | 27         |\n",
            "|    time_elapsed    | 258        |\n",
            "|    total_timesteps | 7040       |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 7.41e+03   |\n",
            "|    critic_loss     | 2.88e+03   |\n",
            "|    ent_coef        | 8.02       |\n",
            "|    ent_coef_loss   | -106       |\n",
            "|    learning_rate   | 0.0003     |\n",
            "|    n_updates       | 6939       |\n",
            "|    reward          | -2.7091844 |\n",
            "-----------------------------------\n",
            "======sac Validation from:  2019-01-02 to  2019-04-03\n",
            "sac Sharpe Ratio:  0.40969072292960185\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_126_1\n",
            "day: 1759, episode: 25\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1204586.22\n",
            "total_reward: 204586.22\n",
            "total_cost: 10691.55\n",
            "total_trades: 5180\n",
            "Sharpe: 0.647\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    fps             | 408        |\n",
            "|    iterations      | 1          |\n",
            "|    time_elapsed    | 5          |\n",
            "|    total_timesteps | 2048       |\n",
            "| train/             |            |\n",
            "|    reward          | 0.01529716 |\n",
            "-----------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 337         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 12          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006454388 |\n",
            "|    clip_fraction        | 0.0427      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.25       |\n",
            "|    explained_variance   | 5.96e-08    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.198       |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00206    |\n",
            "|    reward               | 0.09545733  |\n",
            "|    std                  | 0.997       |\n",
            "|    value_loss           | 0.474       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 343          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 17           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0065217144 |\n",
            "|    clip_fraction        | 0.0597       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.25        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0164       |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00389     |\n",
            "|    reward               | 0.14592469   |\n",
            "|    std                  | 0.998        |\n",
            "|    value_loss           | 0.18         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 326          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 25           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0053295568 |\n",
            "|    clip_fraction        | 0.0272       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.26        |\n",
            "|    explained_variance   | -0.0514      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.501        |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00141     |\n",
            "|    reward               | 0.25106472   |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.76         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 331         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 30          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007607965 |\n",
            "|    clip_fraction        | 0.0506      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.26       |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.279       |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00333    |\n",
            "|    reward               | -0.24686208 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 0.686       |\n",
            "-----------------------------------------\n",
            "======ppo Validation from:  2019-01-02 to  2019-04-03\n",
            "ppo Sharpe Ratio:  0.2553262490304728\n",
            "======Best Model Retraining from:  2012-01-01 to  2019-04-03\n",
            "======Trading from:  2019-04-03 to  2019-07-03\n",
            "============================================\n",
            "turbulence_threshold:  24.528961738292235\n",
            "======Model training from:  2012-01-01 to  2019-04-03\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_189_1\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 269        |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 1          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.3       |\n",
            "|    explained_variance | -0.202     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -13.3      |\n",
            "|    reward             | -1.7331825 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 9.31       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 222       |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 4         |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.31     |\n",
            "|    explained_variance | -0.0459   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | 3.96      |\n",
            "|    reward             | 1.5784417 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 4.58      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 230      |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.31    |\n",
            "|    explained_variance | 0.0318   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | 22.7     |\n",
            "|    reward             | 6.201104 |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 48       |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 241        |\n",
            "|    iterations         | 400        |\n",
            "|    time_elapsed       | 8          |\n",
            "|    total_timesteps    | 2000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.33      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 399        |\n",
            "|    policy_loss        | 4.58       |\n",
            "|    reward             | 0.27190652 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 0.958      |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 248      |\n",
            "|    iterations         | 500      |\n",
            "|    time_elapsed       | 10       |\n",
            "|    total_timesteps    | 2500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.31    |\n",
            "|    explained_variance | -0.0189  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 499      |\n",
            "|    policy_loss        | 1.43     |\n",
            "|    reward             | 0.626003 |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 1.73     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 253        |\n",
            "|    iterations         | 600        |\n",
            "|    time_elapsed       | 11         |\n",
            "|    total_timesteps    | 3000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.3       |\n",
            "|    explained_variance | -0.0288    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 599        |\n",
            "|    policy_loss        | -0.543     |\n",
            "|    reward             | -1.1392787 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.474      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 257        |\n",
            "|    iterations         | 700        |\n",
            "|    time_elapsed       | 13         |\n",
            "|    total_timesteps    | 3500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.28      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 699        |\n",
            "|    policy_loss        | 7.92       |\n",
            "|    reward             | 0.07351364 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 10.4       |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 258          |\n",
            "|    iterations         | 800          |\n",
            "|    time_elapsed       | 15           |\n",
            "|    total_timesteps    | 4000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.28        |\n",
            "|    explained_variance | -0.0119      |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 799          |\n",
            "|    policy_loss        | -11.2        |\n",
            "|    reward             | -0.059048124 |\n",
            "|    std                | 1.01         |\n",
            "|    value_loss         | 6.91         |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 249       |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 18        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.27     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | -11.5     |\n",
            "|    reward             | 2.4003093 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 10.5      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 247       |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 20        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.29     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | -9.7      |\n",
            "|    reward             | 1.3779786 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 6.79      |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 250          |\n",
            "|    iterations         | 1100         |\n",
            "|    time_elapsed       | 21           |\n",
            "|    total_timesteps    | 5500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.29        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1099         |\n",
            "|    policy_loss        | 0.322        |\n",
            "|    reward             | -0.008017109 |\n",
            "|    std                | 1.01         |\n",
            "|    value_loss         | 0.00634      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 251         |\n",
            "|    iterations         | 1200        |\n",
            "|    time_elapsed       | 23          |\n",
            "|    total_timesteps    | 6000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.27       |\n",
            "|    explained_variance | 0.0222      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1199        |\n",
            "|    policy_loss        | -15.5       |\n",
            "|    reward             | -0.06736984 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 19.3        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 253        |\n",
            "|    iterations         | 1300       |\n",
            "|    time_elapsed       | 25         |\n",
            "|    total_timesteps    | 6500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.27      |\n",
            "|    explained_variance | -0.00662   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1299       |\n",
            "|    policy_loss        | 18.3       |\n",
            "|    reward             | -1.7847759 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 33.7       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 255        |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 27         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.27      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | 22         |\n",
            "|    reward             | -3.8725152 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 41.2       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 257        |\n",
            "|    iterations         | 1500       |\n",
            "|    time_elapsed       | 29         |\n",
            "|    total_timesteps    | 7500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.26      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1499       |\n",
            "|    policy_loss        | -2.61      |\n",
            "|    reward             | 0.70730484 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 0.416      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 253        |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 31         |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.26      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | -1.81      |\n",
            "|    reward             | -1.1338736 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 1.83       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 250       |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 33        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.25     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | -11.7     |\n",
            "|    reward             | 0.4129065 |\n",
            "|    std                | 0.999     |\n",
            "|    value_loss         | 6.43      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 251       |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 35        |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.27     |\n",
            "|    explained_variance | -0.00999  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | -35       |\n",
            "|    reward             | 2.0073707 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 118       |\n",
            "-------------------------------------\n",
            "day: 1822, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 2899781.79\n",
            "total_reward: 1899781.79\n",
            "total_cost: 4899.83\n",
            "total_trades: 4275\n",
            "Sharpe: 0.920\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 252        |\n",
            "|    iterations         | 1900       |\n",
            "|    time_elapsed       | 37         |\n",
            "|    total_timesteps    | 9500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.26      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1899       |\n",
            "|    policy_loss        | 1.2        |\n",
            "|    reward             | -2.0702932 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 0.413      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 253         |\n",
            "|    iterations         | 2000        |\n",
            "|    time_elapsed       | 39          |\n",
            "|    total_timesteps    | 10000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.26       |\n",
            "|    explained_variance | 0.165       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1999        |\n",
            "|    policy_loss        | -1.28       |\n",
            "|    reward             | -0.05820525 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 1.55        |\n",
            "---------------------------------------\n",
            "======a2c Validation from:  2019-04-03 to  2019-07-03\n",
            "a2c Sharpe Ratio:  0.15774436443999862\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_189_1\n",
            "day: 1822, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 2544661.80\n",
            "total_reward: 1544661.80\n",
            "total_cost: 998.99\n",
            "total_trades: 1822\n",
            "Sharpe: 0.660\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    episodes        | 4           |\n",
            "|    fps             | 45          |\n",
            "|    time_elapsed    | 159         |\n",
            "|    total_timesteps | 7292        |\n",
            "| train/             |             |\n",
            "|    actor_loss      | 1.7e+03     |\n",
            "|    critic_loss     | 974         |\n",
            "|    learning_rate   | 0.0005      |\n",
            "|    n_updates       | 7191        |\n",
            "|    reward          | -0.73241156 |\n",
            "------------------------------------\n",
            "======ddpg Validation from:  2019-04-03 to  2019-07-03\n",
            "ddpg Sharpe Ratio:  0.12361139053508766\n",
            "======td3 Training========\n",
            "{}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/td3/td3_189_1\n",
            "day: 1822, episode: 15\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1946834.09\n",
            "total_reward: 946834.09\n",
            "total_cost: 999.00\n",
            "total_trades: 1822\n",
            "Sharpe: 0.436\n",
            "=================================\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 269      |\n",
            "|    total_timesteps | 7292     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 5.99e+03 |\n",
            "|    critic_loss     | 1.03e+05 |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 7191     |\n",
            "|    reward          | 3.835583 |\n",
            "---------------------------------\n",
            "======td3 Validation from:  2019-04-03 to  2019-07-03\n",
            "td3 Sharpe Ratio:  -0.02589066344153175\n",
            "======sac Training========\n",
            "{}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/sac/sac_189_1\n",
            "day: 1822, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4377919.07\n",
            "total_reward: 3377919.07\n",
            "total_cost: 999.00\n",
            "total_trades: 3644\n",
            "Sharpe: 1.036\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 27        |\n",
            "|    time_elapsed    | 267       |\n",
            "|    total_timesteps | 7292      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 9.83e+03  |\n",
            "|    critic_loss     | 623       |\n",
            "|    ent_coef        | 8.64      |\n",
            "|    ent_coef_loss   | -158      |\n",
            "|    learning_rate   | 0.0003    |\n",
            "|    n_updates       | 7191      |\n",
            "|    reward          | 1.5486317 |\n",
            "----------------------------------\n",
            "======sac Validation from:  2019-04-03 to  2019-07-03\n",
            "sac Sharpe Ratio:  0.26004667301648227\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_189_1\n",
            "day: 1822, episode: 25\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1347645.19\n",
            "total_reward: 347645.19\n",
            "total_cost: 11439.08\n",
            "total_trades: 5387\n",
            "Sharpe: 0.731\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    fps             | 365         |\n",
            "|    iterations      | 1           |\n",
            "|    time_elapsed    | 5           |\n",
            "|    total_timesteps | 2048        |\n",
            "| train/             |             |\n",
            "|    reward          | 0.036888517 |\n",
            "------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 352          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 11           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034609104 |\n",
            "|    clip_fraction        | 0.0183       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.27        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.529        |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00072     |\n",
            "|    reward               | -0.0080089   |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 1.12         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 330          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 18           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.007389097  |\n",
            "|    clip_fraction        | 0.0658       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.27        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.021       |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00441     |\n",
            "|    reward               | -0.033704884 |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 0.0531       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 334         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 24          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002244487 |\n",
            "|    clip_fraction        | 0.0114      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.28       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.211       |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.000239   |\n",
            "|    reward               | -0.13002962 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 0.552       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 322          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 31           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025675714 |\n",
            "|    clip_fraction        | 0.00317      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.29        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.263        |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.000117    |\n",
            "|    reward               | 0.13616851   |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.613        |\n",
            "------------------------------------------\n",
            "======ppo Validation from:  2019-04-03 to  2019-07-03\n",
            "ppo Sharpe Ratio:  0.28683077329388434\n",
            "======Best Model Retraining from:  2012-01-01 to  2019-07-03\n",
            "======Trading from:  2019-07-03 to  2019-10-02\n",
            "============================================\n",
            "turbulence_threshold:  24.528961738292235\n",
            "======Model training from:  2012-01-01 to  2019-07-03\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_252_1\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 272         |\n",
            "|    iterations         | 100         |\n",
            "|    time_elapsed       | 1           |\n",
            "|    total_timesteps    | 500         |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.38       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 99          |\n",
            "|    policy_loss        | -2.18       |\n",
            "|    reward             | -0.26968795 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 0.262       |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 271           |\n",
            "|    iterations         | 200           |\n",
            "|    time_elapsed       | 3             |\n",
            "|    total_timesteps    | 1000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.38         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 199           |\n",
            "|    policy_loss        | -0.635        |\n",
            "|    reward             | -0.0030661512 |\n",
            "|    std                | 1.04          |\n",
            "|    value_loss         | 0.0489        |\n",
            "-----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 266        |\n",
            "|    iterations         | 300        |\n",
            "|    time_elapsed       | 5          |\n",
            "|    total_timesteps    | 1500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.38      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 299        |\n",
            "|    policy_loss        | -0.733     |\n",
            "|    reward             | 0.15672904 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 0.0757     |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 239           |\n",
            "|    iterations         | 400           |\n",
            "|    time_elapsed       | 8             |\n",
            "|    total_timesteps    | 2000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.41         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 399           |\n",
            "|    policy_loss        | -0.0231       |\n",
            "|    reward             | -0.0013904455 |\n",
            "|    std                | 1.05          |\n",
            "|    value_loss         | 0.00132       |\n",
            "-----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 239        |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 10         |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.4       |\n",
            "|    explained_variance | 2.38e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | 2.85       |\n",
            "|    reward             | -0.7284627 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 0.587      |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 242          |\n",
            "|    iterations         | 600          |\n",
            "|    time_elapsed       | 12           |\n",
            "|    total_timesteps    | 3000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.42        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 599          |\n",
            "|    policy_loss        | 0.01         |\n",
            "|    reward             | -0.109074295 |\n",
            "|    std                | 1.06         |\n",
            "|    value_loss         | 0.257        |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 245       |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 14        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.4      |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | 1.5       |\n",
            "|    reward             | 1.5870583 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 0.359     |\n",
            "-------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 247           |\n",
            "|    iterations         | 800           |\n",
            "|    time_elapsed       | 16            |\n",
            "|    total_timesteps    | 4000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.4          |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 799           |\n",
            "|    policy_loss        | 0.0162        |\n",
            "|    reward             | 0.00021916188 |\n",
            "|    std                | 1.05          |\n",
            "|    value_loss         | 1.91e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 248          |\n",
            "|    iterations         | 900          |\n",
            "|    time_elapsed       | 18           |\n",
            "|    total_timesteps    | 4500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.44        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 899          |\n",
            "|    policy_loss        | 0.0981       |\n",
            "|    reward             | -0.004506278 |\n",
            "|    std                | 1.06         |\n",
            "|    value_loss         | 0.000575     |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 243       |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 20        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.48     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | 1.67      |\n",
            "|    reward             | 0.7078843 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 0.187     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 238       |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 23        |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.48     |\n",
            "|    explained_variance | 0.0174    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | 7.91      |\n",
            "|    reward             | -2.717169 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 6.84      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 240        |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 24         |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.49      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | -0.211     |\n",
            "|    reward             | 0.54735017 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 0.117      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 242         |\n",
            "|    iterations         | 1300        |\n",
            "|    time_elapsed       | 26          |\n",
            "|    total_timesteps    | 6500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.48       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1299        |\n",
            "|    policy_loss        | 0.96        |\n",
            "|    reward             | 0.020075567 |\n",
            "|    std                | 1.08        |\n",
            "|    value_loss         | 2.64        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 239        |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 29         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.47      |\n",
            "|    explained_variance | 0.115      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | 11.5       |\n",
            "|    reward             | -0.6645563 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 14.8       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 237      |\n",
            "|    iterations         | 1500     |\n",
            "|    time_elapsed       | 31       |\n",
            "|    total_timesteps    | 7500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.46    |\n",
            "|    explained_variance | -0.0232  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1499     |\n",
            "|    policy_loss        | 33       |\n",
            "|    reward             | 4.732884 |\n",
            "|    std                | 1.07     |\n",
            "|    value_loss         | 67.5     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 235       |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 33        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.46     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | 3.95      |\n",
            "|    reward             | 1.4530369 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 1.01      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 231       |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 36        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.48     |\n",
            "|    explained_variance | 0.0414    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | 0.462     |\n",
            "|    reward             | 2.9491642 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 1.33      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 233        |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 38         |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.48      |\n",
            "|    explained_variance | -0.0637    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | 6.73       |\n",
            "|    reward             | 0.90557796 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 3.3        |\n",
            "--------------------------------------\n",
            "day: 1885, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 2280617.20\n",
            "total_reward: 1280617.20\n",
            "total_cost: 11268.11\n",
            "total_trades: 4871\n",
            "Sharpe: 0.637\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 235          |\n",
            "|    iterations         | 1900         |\n",
            "|    time_elapsed       | 40           |\n",
            "|    total_timesteps    | 9500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.5         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1899         |\n",
            "|    policy_loss        | 0.0782       |\n",
            "|    reward             | 0.0003724487 |\n",
            "|    std                | 1.08         |\n",
            "|    value_loss         | 0.0112       |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 236       |\n",
            "|    iterations         | 2000      |\n",
            "|    time_elapsed       | 42        |\n",
            "|    total_timesteps    | 10000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.51     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1999      |\n",
            "|    policy_loss        | 0.922     |\n",
            "|    reward             | 1.1361073 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 0.102     |\n",
            "-------------------------------------\n",
            "======a2c Validation from:  2019-07-03 to  2019-10-02\n",
            "a2c Sharpe Ratio:  0.2802674277843604\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_252_1\n",
            "day: 1885, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3800876.28\n",
            "total_reward: 2800876.28\n",
            "total_cost: 999.00\n",
            "total_trades: 5655\n",
            "Sharpe: 0.967\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 4          |\n",
            "|    fps             | 45         |\n",
            "|    time_elapsed    | 164        |\n",
            "|    total_timesteps | 7544       |\n",
            "| train/             |            |\n",
            "|    actor_loss      | -123       |\n",
            "|    critic_loss     | 1.18e+06   |\n",
            "|    learning_rate   | 0.0005     |\n",
            "|    n_updates       | 7443       |\n",
            "|    reward          | -1.9549057 |\n",
            "-----------------------------------\n",
            "======ddpg Validation from:  2019-07-03 to  2019-10-02\n",
            "ddpg Sharpe Ratio:  0.13729769470627753\n",
            "======td3 Training========\n",
            "{}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/td3/td3_252_1\n",
            "day: 1885, episode: 15\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3650793.81\n",
            "total_reward: 2650793.81\n",
            "total_cost: 998.99\n",
            "total_trades: 3770\n",
            "Sharpe: 0.957\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 4          |\n",
            "|    fps             | 27         |\n",
            "|    time_elapsed    | 278        |\n",
            "|    total_timesteps | 7544       |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 1.05e+03   |\n",
            "|    critic_loss     | 194        |\n",
            "|    learning_rate   | 0.001      |\n",
            "|    n_updates       | 7443       |\n",
            "|    reward          | -1.8584524 |\n",
            "-----------------------------------\n",
            "======td3 Validation from:  2019-07-03 to  2019-10-02\n",
            "td3 Sharpe Ratio:  0.14137642411046664\n",
            "======sac Training========\n",
            "{}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/sac/sac_252_1\n",
            "day: 1885, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1545650.24\n",
            "total_reward: 545650.24\n",
            "total_cost: 999.00\n",
            "total_trades: 1885\n",
            "Sharpe: 0.342\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 4          |\n",
            "|    fps             | 27         |\n",
            "|    time_elapsed    | 279        |\n",
            "|    total_timesteps | 7544       |\n",
            "| train/             |            |\n",
            "|    actor_loss      | -3.02e+03  |\n",
            "|    critic_loss     | 236        |\n",
            "|    ent_coef        | 7.59       |\n",
            "|    ent_coef_loss   | -57.2      |\n",
            "|    learning_rate   | 0.0003     |\n",
            "|    n_updates       | 7443       |\n",
            "|    reward          | -0.8913726 |\n",
            "-----------------------------------\n",
            "======sac Validation from:  2019-07-03 to  2019-10-02\n",
            "sac Sharpe Ratio:  0.05769417771380653\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_252_1\n",
            "day: 1885, episode: 25\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1366964.67\n",
            "total_reward: 366964.67\n",
            "total_cost: 12239.57\n",
            "total_trades: 5537\n",
            "Sharpe: 0.821\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    fps             | 402         |\n",
            "|    iterations      | 1           |\n",
            "|    time_elapsed    | 5           |\n",
            "|    total_timesteps | 2048        |\n",
            "| train/             |             |\n",
            "|    reward          | 0.012858368 |\n",
            "------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 299          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 13           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0060680164 |\n",
            "|    clip_fraction        | 0.0466       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.25        |\n",
            "|    explained_variance   | -0.0164      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.3          |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00349     |\n",
            "|    reward               | 0.114429325  |\n",
            "|    std                  | 0.997        |\n",
            "|    value_loss           | 0.882        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 314          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 19           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0064707967 |\n",
            "|    clip_fraction        | 0.0451       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.24        |\n",
            "|    explained_variance   | 0.0659       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.07         |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00385     |\n",
            "|    reward               | -0.11751705  |\n",
            "|    std                  | 0.994        |\n",
            "|    value_loss           | 2.96         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 305         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 26          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.00450402  |\n",
            "|    clip_fraction        | 0.0298      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.25       |\n",
            "|    explained_variance   | -0.0389     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.52        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00236    |\n",
            "|    reward               | -0.28040513 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 3.45        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 312          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 32           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0059790052 |\n",
            "|    clip_fraction        | 0.0543       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.26        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.02         |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00425     |\n",
            "|    reward               | -0.13635138  |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 2.4          |\n",
            "------------------------------------------\n",
            "======ppo Validation from:  2019-07-03 to  2019-10-02\n",
            "ppo Sharpe Ratio:  0.07505185746146993\n",
            "======Best Model Retraining from:  2012-01-01 to  2019-10-02\n",
            "======Trading from:  2019-10-02 to  2020-01-02\n",
            "============================================\n",
            "turbulence_threshold:  24.528961738292235\n",
            "======Model training from:  2012-01-01 to  2019-10-02\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_315_1\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 262       |\n",
            "|    iterations         | 100       |\n",
            "|    time_elapsed       | 1         |\n",
            "|    total_timesteps    | 500       |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.3      |\n",
            "|    explained_variance | -0.0706   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 99        |\n",
            "|    policy_loss        | -8.89     |\n",
            "|    reward             | -1.653083 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 6.8       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 222       |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 4         |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.27     |\n",
            "|    explained_variance | -0.0898   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | 3.33      |\n",
            "|    reward             | 1.8333501 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 4.04      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 231       |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 6         |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.26     |\n",
            "|    explained_variance | 0.0527    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | 16.8      |\n",
            "|    reward             | 5.9066877 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 35.6      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 240         |\n",
            "|    iterations         | 400         |\n",
            "|    time_elapsed       | 8           |\n",
            "|    total_timesteps    | 2000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.25       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 399         |\n",
            "|    policy_loss        | -0.23       |\n",
            "|    reward             | -0.06268277 |\n",
            "|    std                | 0.997       |\n",
            "|    value_loss         | 0.0371      |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 246       |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 10        |\n",
            "|    total_timesteps    | 2500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.25     |\n",
            "|    explained_variance | -0.227    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | 1.96      |\n",
            "|    reward             | -2.571557 |\n",
            "|    std                | 0.999     |\n",
            "|    value_loss         | 1.03      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 251       |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 11        |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.26     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | 20.5      |\n",
            "|    reward             | 1.9005322 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 22.3      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 255       |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 13        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.26     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | 22.6      |\n",
            "|    reward             | 3.6077328 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 39.6      |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 255          |\n",
            "|    iterations         | 800          |\n",
            "|    time_elapsed       | 15           |\n",
            "|    total_timesteps    | 4000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.28        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 799          |\n",
            "|    policy_loss        | 2.39         |\n",
            "|    reward             | -0.046624873 |\n",
            "|    std                | 1.01         |\n",
            "|    value_loss         | 0.616        |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 244       |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 18        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.27     |\n",
            "|    explained_variance | 0.0273    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | 1.46      |\n",
            "|    reward             | 0.5852136 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 0.576     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 246        |\n",
            "|    iterations         | 1000       |\n",
            "|    time_elapsed       | 20         |\n",
            "|    total_timesteps    | 5000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.28      |\n",
            "|    explained_variance | 0.254      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 999        |\n",
            "|    policy_loss        | -2.44      |\n",
            "|    reward             | 0.10036748 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.761      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 248        |\n",
            "|    iterations         | 1100       |\n",
            "|    time_elapsed       | 22         |\n",
            "|    total_timesteps    | 5500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.25      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1099       |\n",
            "|    policy_loss        | 21.4       |\n",
            "|    reward             | -0.2080102 |\n",
            "|    std                | 0.997      |\n",
            "|    value_loss         | 61         |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 250        |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 23         |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.26      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | 2.12       |\n",
            "|    reward             | 0.18193427 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 0.58       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 252       |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 25        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.25     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | -13.7     |\n",
            "|    reward             | 0.4488602 |\n",
            "|    std                | 0.999     |\n",
            "|    value_loss         | 12.6      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 254        |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 27         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.27      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | 12.8       |\n",
            "|    reward             | -1.0347458 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 12.1       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 252        |\n",
            "|    iterations         | 1500       |\n",
            "|    time_elapsed       | 29         |\n",
            "|    total_timesteps    | 7500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.29      |\n",
            "|    explained_variance | -0.000949  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1499       |\n",
            "|    policy_loss        | 4.21       |\n",
            "|    reward             | -7.2198124 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 6.82       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 246        |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 32         |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.31      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | 0.195      |\n",
            "|    reward             | -0.9899595 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.298      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 248       |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 34        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.3      |\n",
            "|    explained_variance | -0.0114   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | -15.7     |\n",
            "|    reward             | 4.9470205 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 16.2      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 249       |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 36        |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.29     |\n",
            "|    explained_variance | 0.0272    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | 5.74      |\n",
            "|    reward             | 1.4525896 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 1.36      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 251       |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 37        |\n",
            "|    total_timesteps    | 9500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.27     |\n",
            "|    explained_variance | -0.0369   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | 18.3      |\n",
            "|    reward             | 1.8972815 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 34.4      |\n",
            "-------------------------------------\n",
            "day: 1948, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3719386.64\n",
            "total_reward: 2719386.64\n",
            "total_cost: 9023.92\n",
            "total_trades: 4480\n",
            "Sharpe: 0.944\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 252        |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 39         |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.29      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | 9.62       |\n",
            "|    reward             | -0.3494317 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 5.59       |\n",
            "--------------------------------------\n",
            "======a2c Validation from:  2019-10-02 to  2020-01-02\n",
            "a2c Sharpe Ratio:  0.41033152955893576\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_315_1\n",
            "day: 1948, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 2997156.62\n",
            "total_reward: 1997156.62\n",
            "total_cost: 998.99\n",
            "total_trades: 1948\n",
            "Sharpe: 0.714\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 46        |\n",
            "|    time_elapsed    | 166       |\n",
            "|    total_timesteps | 7796      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 388       |\n",
            "|    critic_loss     | 25.2      |\n",
            "|    learning_rate   | 0.0005    |\n",
            "|    n_updates       | 7695      |\n",
            "|    reward          | 5.5529985 |\n",
            "----------------------------------\n",
            "======ddpg Validation from:  2019-10-02 to  2020-01-02\n",
            "ddpg Sharpe Ratio:  0.6149495396801921\n",
            "======td3 Training========\n",
            "{}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/td3/td3_315_1\n",
            "day: 1948, episode: 15\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3994699.27\n",
            "total_reward: 2994699.27\n",
            "total_cost: 999.00\n",
            "total_trades: 5844\n",
            "Sharpe: 0.972\n",
            "=================================\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 26       |\n",
            "|    time_elapsed    | 292      |\n",
            "|    total_timesteps | 7796     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.22e+03 |\n",
            "|    critic_loss     | 2.06e+04 |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 7695     |\n",
            "|    reward          | 4.805516 |\n",
            "---------------------------------\n",
            "======td3 Validation from:  2019-10-02 to  2020-01-02\n",
            "td3 Sharpe Ratio:  0.5244836800628078\n",
            "======sac Training========\n",
            "{}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/sac/sac_315_1\n",
            "day: 1948, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1000000.00\n",
            "total_reward: 0.00\n",
            "total_cost: 0.00\n",
            "total_trades: 0\n",
            "=================================\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 282      |\n",
            "|    total_timesteps | 7796     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.13e+04 |\n",
            "|    critic_loss     | 2.02e+04 |\n",
            "|    ent_coef        | 10.7     |\n",
            "|    ent_coef_loss   | -120     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 7695     |\n",
            "|    reward          | 0.0      |\n",
            "---------------------------------\n",
            "======sac Validation from:  2019-10-02 to  2020-01-02\n",
            "sac Sharpe Ratio:  0.0\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_315_1\n",
            "day: 1948, episode: 25\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1209782.33\n",
            "total_reward: 209782.33\n",
            "total_cost: 12692.79\n",
            "total_trades: 5770\n",
            "Sharpe: 0.631\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    fps             | 319        |\n",
            "|    iterations      | 1          |\n",
            "|    time_elapsed    | 6          |\n",
            "|    total_timesteps | 2048       |\n",
            "| train/             |            |\n",
            "|    reward          | 0.05793994 |\n",
            "-----------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 326          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 12           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052955397 |\n",
            "|    clip_fraction        | 0.0478       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.27        |\n",
            "|    explained_variance   | -0.000564    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0923       |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00327     |\n",
            "|    reward               | 0.03916287   |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.405        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 307          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 19           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044653025 |\n",
            "|    clip_fraction        | 0.016        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.28        |\n",
            "|    explained_variance   | -0.0262      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 4.79         |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00318     |\n",
            "|    reward               | 0.009617147  |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 10.3         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 317           |\n",
            "|    iterations           | 4             |\n",
            "|    time_elapsed         | 25            |\n",
            "|    total_timesteps      | 8192          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00076827104 |\n",
            "|    clip_fraction        | 0.00654       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -4.28         |\n",
            "|    explained_variance   | 0.0792        |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.405         |\n",
            "|    n_updates            | 30            |\n",
            "|    policy_gradient_loss | 0.000187      |\n",
            "|    reward               | 0.028219659   |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 1.39          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 308          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 33           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0065028416 |\n",
            "|    clip_fraction        | 0.0441       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.28        |\n",
            "|    explained_variance   | 0.234        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 3.93         |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00603     |\n",
            "|    reward               | -0.39833152  |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 6.75         |\n",
            "------------------------------------------\n",
            "======ppo Validation from:  2019-10-02 to  2020-01-02\n",
            "ppo Sharpe Ratio:  0.5154602998458114\n",
            "======Best Model Retraining from:  2012-01-01 to  2020-01-02\n",
            "======Trading from:  2020-01-02 to  2020-04-02\n",
            "============================================\n",
            "turbulence_threshold:  24.528961738292235\n",
            "======Model training from:  2012-01-01 to  2020-01-02\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_378_1\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 267        |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 1          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.31      |\n",
            "|    explained_variance | -0.151     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -7.56      |\n",
            "|    reward             | -0.9048355 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 3.23       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 270       |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 3         |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.32     |\n",
            "|    explained_variance | 0.0769    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | 3.03      |\n",
            "|    reward             | 1.9348994 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 2.34      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 275      |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.31    |\n",
            "|    explained_variance | 0.0356   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | 19.4     |\n",
            "|    reward             | 5.292158 |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 30.3     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 272       |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 7         |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.3      |\n",
            "|    explained_variance | 0.0368    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | 8.05      |\n",
            "|    reward             | 4.1240277 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 25.5      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 248        |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 10         |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.31      |\n",
            "|    explained_variance | 0.356      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | 4.16       |\n",
            "|    reward             | -1.6669792 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 1.5        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 244       |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 12        |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.3      |\n",
            "|    explained_variance | 0.0557    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | 4.19      |\n",
            "|    reward             | 5.2593145 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 1.53      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 246       |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 14        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.3      |\n",
            "|    explained_variance | -0.0819   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | 10.3      |\n",
            "|    reward             | -3.839024 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 9.19      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 249      |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 16       |\n",
            "|    total_timesteps    | 4000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.31    |\n",
            "|    explained_variance | -0.00417 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | 49.7     |\n",
            "|    reward             | 4.338588 |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 105      |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 251       |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 17        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.32     |\n",
            "|    explained_variance | 0.0103    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | 3.85      |\n",
            "|    reward             | 0.8337339 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 2.25      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 252        |\n",
            "|    iterations         | 1000       |\n",
            "|    time_elapsed       | 19         |\n",
            "|    total_timesteps    | 5000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.34      |\n",
            "|    explained_variance | 0.00403    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 999        |\n",
            "|    policy_loss        | -8.51      |\n",
            "|    reward             | -0.5504356 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 5.11       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 251        |\n",
            "|    iterations         | 1100       |\n",
            "|    time_elapsed       | 21         |\n",
            "|    total_timesteps    | 5500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.37      |\n",
            "|    explained_variance | -0.0287    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1099       |\n",
            "|    policy_loss        | 3.55       |\n",
            "|    reward             | -0.4962302 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 2.51       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 243       |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 24        |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.35     |\n",
            "|    explained_variance | 0.000129  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | 15.2      |\n",
            "|    reward             | 0.4298307 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 47        |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 245      |\n",
            "|    iterations         | 1300     |\n",
            "|    time_elapsed       | 26       |\n",
            "|    total_timesteps    | 6500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.35    |\n",
            "|    explained_variance | 0.042    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1299     |\n",
            "|    policy_loss        | 9.55     |\n",
            "|    reward             | 4.478014 |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 7.34     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 246        |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 28         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.35      |\n",
            "|    explained_variance | 0.00372    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | 51.6       |\n",
            "|    reward             | -1.3655833 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 131        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 248       |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 30        |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.36     |\n",
            "|    explained_variance | 0.0676    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | 2.49      |\n",
            "|    reward             | 1.2411957 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 1.46      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 249        |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 32         |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.34      |\n",
            "|    explained_variance | -0.0228    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | 21.6       |\n",
            "|    reward             | -5.8436093 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 33.2       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 250        |\n",
            "|    iterations         | 1700       |\n",
            "|    time_elapsed       | 33         |\n",
            "|    total_timesteps    | 8500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.33      |\n",
            "|    explained_variance | 0.0228     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1699       |\n",
            "|    policy_loss        | 9.24       |\n",
            "|    reward             | 0.53997904 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 2.04       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 248      |\n",
            "|    iterations         | 1800     |\n",
            "|    time_elapsed       | 36       |\n",
            "|    total_timesteps    | 9000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.34    |\n",
            "|    explained_variance | -0.0283  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | 5.32     |\n",
            "|    reward             | 0.930492 |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 13.8     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 244       |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 38        |\n",
            "|    total_timesteps    | 9500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.34     |\n",
            "|    explained_variance | 0.0493    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | 6.87      |\n",
            "|    reward             | 0.9579251 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 3.59      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 245       |\n",
            "|    iterations         | 2000      |\n",
            "|    time_elapsed       | 40        |\n",
            "|    total_timesteps    | 10000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.34     |\n",
            "|    explained_variance | -0.00774  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1999      |\n",
            "|    policy_loss        | -23.3     |\n",
            "|    reward             | 1.2290009 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 29        |\n",
            "-------------------------------------\n",
            "======a2c Validation from:  2020-01-02 to  2020-04-02\n",
            "a2c Sharpe Ratio:  -0.1200563361000484\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_378_1\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 4          |\n",
            "|    fps             | 47         |\n",
            "|    time_elapsed    | 170        |\n",
            "|    total_timesteps | 8048       |\n",
            "| train/             |            |\n",
            "|    actor_loss      | -1.55e+03  |\n",
            "|    critic_loss     | 38.6       |\n",
            "|    learning_rate   | 0.0005     |\n",
            "|    n_updates       | 7947       |\n",
            "|    reward          | -12.054909 |\n",
            "-----------------------------------\n",
            "======ddpg Validation from:  2020-01-02 to  2020-04-02\n",
            "ddpg Sharpe Ratio:  -0.057876392988298435\n",
            "======td3 Training========\n",
            "{}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/td3/td3_378_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 27        |\n",
            "|    time_elapsed    | 294       |\n",
            "|    total_timesteps | 8048      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -520      |\n",
            "|    critic_loss     | 68.6      |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 7947      |\n",
            "|    reward          | 0.8338644 |\n",
            "----------------------------------\n",
            "======td3 Validation from:  2020-01-02 to  2020-04-02\n",
            "td3 Sharpe Ratio:  -0.08883458754665745\n",
            "======sac Training========\n",
            "{}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/sac/sac_378_1\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 4          |\n",
            "|    fps             | 27         |\n",
            "|    time_elapsed    | 297        |\n",
            "|    total_timesteps | 8048       |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 8.65e+03   |\n",
            "|    critic_loss     | 761        |\n",
            "|    ent_coef        | 10.4       |\n",
            "|    ent_coef_loss   | -119       |\n",
            "|    learning_rate   | 0.0003     |\n",
            "|    n_updates       | 7947       |\n",
            "|    reward          | -4.1218534 |\n",
            "-----------------------------------\n",
            "======sac Validation from:  2020-01-02 to  2020-04-02\n",
            "sac Sharpe Ratio:  -0.1712469864162348\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_378_1\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    fps             | 318         |\n",
            "|    iterations      | 1           |\n",
            "|    time_elapsed    | 6           |\n",
            "|    total_timesteps | 2048        |\n",
            "| train/             |             |\n",
            "|    reward          | 0.034077577 |\n",
            "------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 336           |\n",
            "|    iterations           | 2             |\n",
            "|    time_elapsed         | 12            |\n",
            "|    total_timesteps      | 4096          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.004195906   |\n",
            "|    clip_fraction        | 0.0293        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -4.24         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.698         |\n",
            "|    n_updates            | 10            |\n",
            "|    policy_gradient_loss | -0.00189      |\n",
            "|    reward               | -0.0048645483 |\n",
            "|    std                  | 0.992         |\n",
            "|    value_loss           | 1.6           |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 317          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 19           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035553216 |\n",
            "|    clip_fraction        | 0.00996      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.23        |\n",
            "|    explained_variance   | -0.00256     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.47         |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.000849    |\n",
            "|    reward               | 0.074476965  |\n",
            "|    std                  | 0.993        |\n",
            "|    value_loss           | 5.18         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 326          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 25           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0066073444 |\n",
            "|    clip_fraction        | 0.0485       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.23        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.165        |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00263     |\n",
            "|    reward               | 0.09601854   |\n",
            "|    std                  | 0.991        |\n",
            "|    value_loss           | 0.608        |\n",
            "------------------------------------------\n",
            "day: 2011, episode: 25\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 2670057.44\n",
            "total_reward: 1670057.44\n",
            "total_cost: 13755.19\n",
            "total_trades: 5971\n",
            "Sharpe: 1.029\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 316           |\n",
            "|    iterations           | 5             |\n",
            "|    time_elapsed         | 32            |\n",
            "|    total_timesteps      | 10240         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0038851677  |\n",
            "|    clip_fraction        | 0.00625       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -4.23         |\n",
            "|    explained_variance   | 0.0187        |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 3.39          |\n",
            "|    n_updates            | 40            |\n",
            "|    policy_gradient_loss | -0.000818     |\n",
            "|    reward               | -0.0025428478 |\n",
            "|    std                  | 0.991         |\n",
            "|    value_loss           | 7.24          |\n",
            "-------------------------------------------\n",
            "======ppo Validation from:  2020-01-02 to  2020-04-02\n",
            "ppo Sharpe Ratio:  -0.08147678201513792\n",
            "======Best Model Retraining from:  2012-01-01 to  2020-04-02\n",
            "======Trading from:  2020-04-02 to  2020-07-02\n",
            "============================================\n",
            "turbulence_threshold:  24.528961738292235\n",
            "======Model training from:  2012-01-01 to  2020-04-02\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_441_1\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 276         |\n",
            "|    iterations         | 100         |\n",
            "|    time_elapsed       | 1           |\n",
            "|    total_timesteps    | 500         |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.26       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 99          |\n",
            "|    policy_loss        | -1.36       |\n",
            "|    reward             | -0.19322844 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 0.131       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 275        |\n",
            "|    iterations         | 200        |\n",
            "|    time_elapsed       | 3          |\n",
            "|    total_timesteps    | 1000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.26      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 199        |\n",
            "|    policy_loss        | -0.901     |\n",
            "|    reward             | -0.4110531 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 0.261      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 276       |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 5         |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.27     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | 4.09      |\n",
            "|    reward             | 0.4065551 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 1.66      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 279       |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 7         |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.27     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | 1.61      |\n",
            "|    reward             | 1.1321553 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 0.391     |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 271          |\n",
            "|    iterations         | 500          |\n",
            "|    time_elapsed       | 9            |\n",
            "|    total_timesteps    | 2500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.29        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 499          |\n",
            "|    policy_loss        | -0.06        |\n",
            "|    reward             | -0.005342022 |\n",
            "|    std                | 1.01         |\n",
            "|    value_loss         | 0.000257     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 253         |\n",
            "|    iterations         | 600         |\n",
            "|    time_elapsed       | 11          |\n",
            "|    total_timesteps    | 3000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.32       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 599         |\n",
            "|    policy_loss        | 0.0241      |\n",
            "|    reward             | 0.024629198 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 3.61e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 255          |\n",
            "|    iterations         | 700          |\n",
            "|    time_elapsed       | 13           |\n",
            "|    total_timesteps    | 3500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.38        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 699          |\n",
            "|    policy_loss        | 0.00255      |\n",
            "|    reward             | 0.0063468902 |\n",
            "|    std                | 1.04         |\n",
            "|    value_loss         | 0.000797     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 258         |\n",
            "|    iterations         | 800         |\n",
            "|    time_elapsed       | 15          |\n",
            "|    total_timesteps    | 4000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.42       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 799         |\n",
            "|    policy_loss        | -0.293      |\n",
            "|    reward             | -0.09180321 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 0.0567      |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 260       |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 17        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.45     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | 1.55      |\n",
            "|    reward             | 1.389036  |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 0.926     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 262        |\n",
            "|    iterations         | 1000       |\n",
            "|    time_elapsed       | 19         |\n",
            "|    total_timesteps    | 5000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.46      |\n",
            "|    explained_variance | 1.79e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 999        |\n",
            "|    policy_loss        | 17.6       |\n",
            "|    reward             | -1.6376183 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 21.9       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 264         |\n",
            "|    iterations         | 1100        |\n",
            "|    time_elapsed       | 20          |\n",
            "|    total_timesteps    | 5500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.46       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1099        |\n",
            "|    policy_loss        | -12.6       |\n",
            "|    reward             | -0.47771573 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 31          |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 259        |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 23         |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.47      |\n",
            "|    explained_variance | -0.00192   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | 21.7       |\n",
            "|    reward             | -4.6251845 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 29.8       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 254        |\n",
            "|    iterations         | 1300       |\n",
            "|    time_elapsed       | 25         |\n",
            "|    total_timesteps    | 6500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.49      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1299       |\n",
            "|    policy_loss        | 0.274      |\n",
            "|    reward             | 0.12381494 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 0.0106     |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 255       |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 27        |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.51     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | 5.56      |\n",
            "|    reward             | 1.8784807 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 2.98      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 257         |\n",
            "|    iterations         | 1500        |\n",
            "|    time_elapsed       | 29          |\n",
            "|    total_timesteps    | 7500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.51       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1499        |\n",
            "|    policy_loss        | 5.61        |\n",
            "|    reward             | -0.43884534 |\n",
            "|    std                | 1.09        |\n",
            "|    value_loss         | 2.77        |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 258      |\n",
            "|    iterations         | 1600     |\n",
            "|    time_elapsed       | 30       |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.52    |\n",
            "|    explained_variance | 5.96e-08 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1599     |\n",
            "|    policy_loss        | -0.104   |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 1.09     |\n",
            "|    value_loss         | 0.000518 |\n",
            "------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 260            |\n",
            "|    iterations         | 1700           |\n",
            "|    time_elapsed       | 32             |\n",
            "|    total_timesteps    | 8500           |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -4.55          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 1699           |\n",
            "|    policy_loss        | 0.0044         |\n",
            "|    reward             | -1.4572869e-05 |\n",
            "|    std                | 1.1            |\n",
            "|    value_loss         | 7.73e-07       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 261           |\n",
            "|    iterations         | 1800          |\n",
            "|    time_elapsed       | 34            |\n",
            "|    total_timesteps    | 9000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.61         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1799          |\n",
            "|    policy_loss        | -0.0176       |\n",
            "|    reward             | -0.0009221669 |\n",
            "|    std                | 1.12          |\n",
            "|    value_loss         | 1.05e-05      |\n",
            "-----------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 257      |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 36       |\n",
            "|    total_timesteps    | 9500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.69    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | 0.000471 |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 1.16     |\n",
            "|    value_loss         | 1.26e-08 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 254      |\n",
            "|    iterations         | 2000     |\n",
            "|    time_elapsed       | 39       |\n",
            "|    total_timesteps    | 10000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.81    |\n",
            "|    explained_variance | 5.96e-08 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1999     |\n",
            "|    policy_loss        | 0.00788  |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 1.2      |\n",
            "|    value_loss         | 4e-06    |\n",
            "------------------------------------\n",
            "======a2c Validation from:  2020-04-02 to  2020-07-02\n",
            "a2c Sharpe Ratio:  0.09297209678171668\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_441_1\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 4          |\n",
            "|    fps             | 45         |\n",
            "|    time_elapsed    | 180        |\n",
            "|    total_timesteps | 8300       |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 1.65e+03   |\n",
            "|    critic_loss     | 36.1       |\n",
            "|    learning_rate   | 0.0005     |\n",
            "|    n_updates       | 8199       |\n",
            "|    reward          | -19.676706 |\n",
            "-----------------------------------\n",
            "======ddpg Validation from:  2020-04-02 to  2020-07-02\n",
            "ddpg Sharpe Ratio:  0.40334155968707236\n",
            "======td3 Training========\n",
            "{}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/td3/td3_441_1\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 4          |\n",
            "|    fps             | 27         |\n",
            "|    time_elapsed    | 306        |\n",
            "|    total_timesteps | 8300       |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 3.84e+03   |\n",
            "|    critic_loss     | 5.75e+03   |\n",
            "|    learning_rate   | 0.001      |\n",
            "|    n_updates       | 8199       |\n",
            "|    reward          | -16.984564 |\n",
            "-----------------------------------\n",
            "======td3 Validation from:  2020-04-02 to  2020-07-02\n",
            "td3 Sharpe Ratio:  0.4009775514922075\n",
            "======sac Training========\n",
            "{}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/sac/sac_441_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 28        |\n",
            "|    time_elapsed    | 295       |\n",
            "|    total_timesteps | 8300      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.51e+04 |\n",
            "|    critic_loss     | 5.14e+04  |\n",
            "|    ent_coef        | 11.7      |\n",
            "|    ent_coef_loss   | -69.5     |\n",
            "|    learning_rate   | 0.0003    |\n",
            "|    n_updates       | 8199      |\n",
            "|    reward          | 0.0       |\n",
            "----------------------------------\n",
            "======sac Validation from:  2020-04-02 to  2020-07-02\n",
            "sac Sharpe Ratio:  0.0\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_441_1\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    fps             | 325        |\n",
            "|    iterations      | 1          |\n",
            "|    time_elapsed    | 6          |\n",
            "|    total_timesteps | 2048       |\n",
            "| train/             |            |\n",
            "|    reward          | 0.93055177 |\n",
            "-----------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 341          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 12           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030234326 |\n",
            "|    clip_fraction        | 0.0185       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.25        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.42         |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.000981    |\n",
            "|    reward               | -1.7069587   |\n",
            "|    std                  | 0.996        |\n",
            "|    value_loss           | 0.8          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 325          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 18           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029839128 |\n",
            "|    clip_fraction        | 0.0159       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.24        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.18         |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.0011      |\n",
            "|    reward               | 0.22169094   |\n",
            "|    std                  | 0.993        |\n",
            "|    value_loss           | 3.52         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 331         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 24          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004887944 |\n",
            "|    clip_fraction        | 0.0531      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.24       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 5.92        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00163    |\n",
            "|    reward               | 3.6802204   |\n",
            "|    std                  | 0.994       |\n",
            "|    value_loss           | 5.52        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 324         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 31          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003569009 |\n",
            "|    clip_fraction        | 0.0268      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.25       |\n",
            "|    explained_variance   | -0.00843    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 4.29        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00193    |\n",
            "|    reward               | 0.27925783  |\n",
            "|    std                  | 0.999       |\n",
            "|    value_loss           | 6.28        |\n",
            "-----------------------------------------\n",
            "======ppo Validation from:  2020-04-02 to  2020-07-02\n",
            "ppo Sharpe Ratio:  0.47985757681235536\n",
            "======Best Model Retraining from:  2012-01-01 to  2020-07-02\n",
            "======Trading from:  2020-07-02 to  2020-10-01\n",
            "============================================\n",
            "turbulence_threshold:  24.528961738292235\n",
            "======Model training from:  2012-01-01 to  2020-07-02\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_504_1\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 280         |\n",
            "|    iterations         | 100         |\n",
            "|    time_elapsed       | 1           |\n",
            "|    total_timesteps    | 500         |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.33       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 99          |\n",
            "|    policy_loss        | -4.28       |\n",
            "|    reward             | -0.83781415 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 2.43        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 274       |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 3         |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.33     |\n",
            "|    explained_variance | 0.00652   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | 1.46      |\n",
            "|    reward             | 1.6400062 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 2.08      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 276       |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 5         |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.32     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | 11.8      |\n",
            "|    reward             | 4.7663846 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 22.8      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 276       |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 7         |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.31     |\n",
            "|    explained_variance | 0.0251    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | 12.8      |\n",
            "|    reward             | 4.1882854 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 28.3      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 273        |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 9          |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.34      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | -1.17      |\n",
            "|    reward             | -0.3275032 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 0.167      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 254        |\n",
            "|    iterations         | 600        |\n",
            "|    time_elapsed       | 11         |\n",
            "|    total_timesteps    | 3000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.35      |\n",
            "|    explained_variance | 0.16       |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 599        |\n",
            "|    policy_loss        | -4         |\n",
            "|    reward             | -1.9617186 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 1.22       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 250        |\n",
            "|    iterations         | 700        |\n",
            "|    time_elapsed       | 13         |\n",
            "|    total_timesteps    | 3500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.35      |\n",
            "|    explained_variance | -0.148     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 699        |\n",
            "|    policy_loss        | 2.19       |\n",
            "|    reward             | 0.48378515 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 2.29       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 254       |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 15        |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.36     |\n",
            "|    explained_variance | -0.129    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | -8.05     |\n",
            "|    reward             | 1.0023752 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 6.12      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 255         |\n",
            "|    iterations         | 900         |\n",
            "|    time_elapsed       | 17          |\n",
            "|    total_timesteps    | 4500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.36       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 899         |\n",
            "|    policy_loss        | -1.02       |\n",
            "|    reward             | 0.092366725 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.119       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 257         |\n",
            "|    iterations         | 1000        |\n",
            "|    time_elapsed       | 19          |\n",
            "|    total_timesteps    | 5000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.34       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 999         |\n",
            "|    policy_loss        | -0.396      |\n",
            "|    reward             | -0.20663291 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.0222      |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 260      |\n",
            "|    iterations         | 1100     |\n",
            "|    time_elapsed       | 21       |\n",
            "|    total_timesteps    | 5500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.37    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1099     |\n",
            "|    policy_loss        | -15.1    |\n",
            "|    reward             | -4.71418 |\n",
            "|    std                | 1.04     |\n",
            "|    value_loss         | 16.4     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 261       |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 22        |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.36     |\n",
            "|    explained_variance | -0.018    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | -8.06     |\n",
            "|    reward             | 4.5371704 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 20.2      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 253         |\n",
            "|    iterations         | 1300        |\n",
            "|    time_elapsed       | 25          |\n",
            "|    total_timesteps    | 6500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.34       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1299        |\n",
            "|    policy_loss        | -0.174      |\n",
            "|    reward             | -0.32658747 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.0305      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 251        |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 27         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.37      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | 6.83       |\n",
            "|    reward             | -1.1143761 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 4.2        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 253        |\n",
            "|    iterations         | 1500       |\n",
            "|    time_elapsed       | 29         |\n",
            "|    total_timesteps    | 7500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.39      |\n",
            "|    explained_variance | -0.125     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1499       |\n",
            "|    policy_loss        | -6.91      |\n",
            "|    reward             | -0.8763675 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 2.12       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 255        |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 31         |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.37      |\n",
            "|    explained_variance | -0.024     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | 18         |\n",
            "|    reward             | 0.26042086 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 21.2       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 256        |\n",
            "|    iterations         | 1700       |\n",
            "|    time_elapsed       | 33         |\n",
            "|    total_timesteps    | 8500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.37      |\n",
            "|    explained_variance | -0.0395    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1699       |\n",
            "|    policy_loss        | 19.3       |\n",
            "|    reward             | -7.7278695 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 196        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 256       |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 35        |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.38     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | -2.44     |\n",
            "|    reward             | 1.4530537 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 0.425     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 257       |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 36        |\n",
            "|    total_timesteps    | 9500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.39     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | -0.00578  |\n",
            "|    reward             | 2.4558334 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 1.91      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 252        |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 39         |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.37      |\n",
            "|    explained_variance | 0.00556    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | -7.74      |\n",
            "|    reward             | -1.3626333 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 11.7       |\n",
            "--------------------------------------\n",
            "======a2c Validation from:  2020-07-02 to  2020-10-01\n",
            "a2c Sharpe Ratio:  0.042359783494252734\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_504_1\n"
          ]
        }
      ]
    }
  ]
}